{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "a1w4YdHMXooX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import json\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import f1_score\n",
        "import gensim.downloader as api\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load pre-trained word embeddings\n",
        "word_vectors = api.load(\"word2vec-google-news-300\")\n",
        "glove_vectors = api.load(\"glove-wiki-gigaword-300\")\n",
        "fasttext_vectors = api.load(\"fasttext-wiki-news-subwords-300\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZvAZoKP_XooY"
      },
      "outputs": [],
      "source": [
        "class RNNModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, tagset_size, word_embeddings):\n",
        "        super(RNNModel, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(word_embeddings, freeze=True)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.embedding(sentence)\n",
        "        rnn_out, _ = self.rnn(embeds)\n",
        "        tag_space = self.linear(rnn_out)\n",
        "        return tag_space\n",
        "    \n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, tagset_size, word_embeddings):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(word_embeddings, freeze=True)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.embedding(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds)\n",
        "        tag_space = self.linear(lstm_out)\n",
        "        return tag_space\n",
        "    \n",
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, tagset_size, word_embeddings):\n",
        "        super(GRUModel, self).__init__()\n",
        "        self.embedding = nn.Embedding.from_pretrained(word_embeddings, freeze=True)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.embedding(sentence)\n",
        "        gru_out, _ = self.gru(embeds)\n",
        "        tag_space = self.linear(gru_out)\n",
        "        return tag_space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "word2vec_state_dict = torch.load('t2_model1_word2vec.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "glove_state_dict = torch.load('t2_model1_GloVe.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "fasttext_state_dict = torch.load('t2_model1_fasttext.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "word2vec_state_dict2 = torch.load('t2_model2_word2vec.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "glove_state_dict2 = torch.load('t2_model2_GloVe.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "fasttext_state_dict2 = torch.load('t2_model2_fasttext.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "word2vec_state_dict3 = torch.load('t2_model3_word2vec.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "glove_state_dict3 = torch.load('t2_model3_GloVe.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lp6c4nL1XooZ"
      },
      "outputs": [],
      "source": [
        "fasttext_state_dict3 = torch.load('t2_model3_fasttext.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "word2vec_model = RNNModel(word_vectors.vector_size, 128, 3, torch.FloatTensor(word_vectors.vectors))\n",
        "glove_model = RNNModel(glove_vectors.vector_size, 128, 3, torch.FloatTensor(glove_vectors.vectors))\n",
        "fasttext_model = RNNModel(fasttext_vectors.vector_size, 128, 3, torch.FloatTensor(fasttext_vectors.vectors))\n",
        "\n",
        "word2vec_model2 = LSTMModel(word_vectors.vector_size, 128, 3, torch.FloatTensor(word_vectors.vectors))\n",
        "glove_model2 = LSTMModel(glove_vectors.vector_size, 128, 3, torch.FloatTensor(glove_vectors.vectors))\n",
        "fasttext_model2 = LSTMModel(fasttext_vectors.vector_size, 128, 3, torch.FloatTensor(fasttext_vectors.vectors))\n",
        "\n",
        "word2vec_model3 = GRUModel(word_vectors.vector_size, 128, 3, torch.FloatTensor(word_vectors.vectors))\n",
        "glove_model3 = GRUModel(glove_vectors.vector_size, 128, 3, torch.FloatTensor(glove_vectors.vectors))\n",
        "fasttext_model3 = GRUModel(fasttext_vectors.vector_size, 128, 3, torch.FloatTensor(fasttext_vectors.vectors))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word2vec_model.load_state_dict(word2vec_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "glove_model.load_state_dict(glove_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "n_unAJqcXooZ",
        "outputId": "e19bdd67-34d9-412f-b428-ebf2fcad6dfa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fasttext_model.load_state_dict(fasttext_state_dict)\n",
        "\n",
        "word2vec_model2.load_state_dict(word2vec_state_dict2)\n",
        "glove_model2.load_state_dict(glove_state_dict2)\n",
        "fasttext_model2.load_state_dict(fasttext_state_dict2)\n",
        "\n",
        "word2vec_model3.load_state_dict(word2vec_state_dict3)\n",
        "glove_model3.load_state_dict(glove_state_dict3)\n",
        "fasttext_model3.load_state_dict(fasttext_state_dict3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4wY5UhtEXooa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import json\n",
        "\n",
        "def load_dataset(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "    return data\n",
        "\n",
        "def prepare_data(data, word_to_idx, label_to_idx):\n",
        "    X, y = [], []\n",
        "    for sample in data.values():\n",
        "        text = sample['text'].split()\n",
        "        labels = sample['labels']\n",
        "        text_indices = [word_to_idx.get(word, 0) for word in text]\n",
        "        X.append(torch.tensor(text_indices))\n",
        "        y.append(torch.tensor([label_to_idx.get(label, -1) for label in labels if label in label_to_idx]))\n",
        "    X_padded = pad_sequence(X, batch_first=True, padding_value=0)\n",
        "    y_padded = pad_sequence(y, batch_first=True, padding_value=0)\n",
        "    return X_padded, y_padded\n",
        "\n",
        "test_data = load_dataset('ATE_test.json')\n",
        "\n",
        "word_to_idx_word2vec = {word: idx + 1 for idx, word in enumerate(word_vectors.index_to_key)}\n",
        "word_to_idx_glove = {word: idx + 1 for idx, word in enumerate(glove_vectors.index_to_key)}\n",
        "word_to_idx_fasttext = {word: idx + 1 for idx, word in enumerate(fasttext_vectors.index_to_key)}\n",
        "label_to_idx = label_to_ix = {'B':0, 'I':1, 'O':2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DnimKcfPXooa",
        "outputId": "6e1fac7d-ca41-4eb6-f0ec-b2220a165c3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "T2 Model 1 Word2Vec Test Accuracy: 0.9636293369975953  Test F1 Score: 0.6418273258905921\n",
            "T2 Model 1 GloVe Test Accuracy: 0.9705427688079697  Test F1 Score: 0.7345606849465055\n",
            "T2 Model 1 Fasttext Test Accuracy: 0.9688680865681897  Test F1 Score: 0.642376971497277\n",
            "T2 Model 2 Word2Vec Test Accuracy: 0.9644881484026108  Test F1 Score: 0.6326217148585592\n",
            "T2 Model 2 GloVe Test Accuracy: 0.9692545517004466  Test F1 Score: 0.643781609162235\n",
            "T2 Model 2 Fasttext Test Accuracy: 0.968610443146685  Test F1 Score: 0.6368809473533991\n",
            "T2 Model 3 Word2Vec Test Accuracy: 0.965218138096874  Test F1 Score: 0.6331449380684212\n",
            "T2 Model 3 GloVe Test Accuracy: 0.9709721745104775  Test F1 Score: 0.7176116417133045\n",
            "T2 Model 3 Fasttext Test Accuracy: 0.9688680865681897  Test F1 Score: 0.6371674868854306\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model2(model, dataloader, tagset_size):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for text, labels in dataloader:\n",
        "            outputs = model(text)\n",
        "            loss = criterion(outputs.view(-1, tagset_size), labels.view(-1))\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 2)\n",
        "            all_preds.extend(predicted.view(-1).cpu().numpy().tolist())\n",
        "            all_labels.extend(labels.view(-1).cpu().numpy().tolist())\n",
        "    macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "\n",
        "    return accuracy, macro_f1\n",
        "\n",
        "X_test_word2vec, y_test_word2vec = prepare_data(test_data, word_to_idx_word2vec, label_to_idx)\n",
        "test_dataset_word2vec = TensorDataset(X_test_word2vec, y_test_word2vec)\n",
        "test_loader_word2vec = DataLoader(test_dataset_word2vec, batch_size=32, shuffle=True)\n",
        "\n",
        "word2vec_accuracy, word2vec_f1 = evaluate_model2(word2vec_model, test_loader_word2vec, 3)\n",
        "word2vec_accuracy2, word2vec_f12 = evaluate_model2(word2vec_model2, test_loader_word2vec, 3)\n",
        "word2vec_accuracy3, word2vec_f13 = evaluate_model2(word2vec_model3, test_loader_word2vec, 3)\n",
        "\n",
        "\n",
        "X_test_glove, y_test_glove = prepare_data(test_data, word_to_idx_glove, label_to_idx)\n",
        "test_dataset_glove = TensorDataset(X_test_glove, y_test_glove)\n",
        "test_loader_glove = DataLoader(test_dataset_glove, batch_size=32, shuffle=True)\n",
        "\n",
        "glove_accuracy, glove_f1 = evaluate_model2(glove_model, test_loader_glove, 3)\n",
        "glove_accuracy2, glove_f12 = evaluate_model2(glove_model2, test_loader_glove, 3)\n",
        "glove_accuracy3, glove_f13 = evaluate_model2(glove_model3, test_loader_glove, 3)\n",
        "\n",
        "\n",
        "X_test_fasttext, y_test_fasttext = prepare_data(test_data, word_to_idx_fasttext, label_to_idx)\n",
        "test_dataset_fasttext = TensorDataset(X_test_fasttext, y_test_fasttext)\n",
        "test_loader_fasttext = DataLoader(test_dataset_fasttext, batch_size=32, shuffle=True)\n",
        "\n",
        "fasttext_accuracy, fasttext_f1 = evaluate_model2(fasttext_model, test_loader_fasttext, 3)\n",
        "fasttext_accuracy2, fasttext_f12 = evaluate_model2(fasttext_model2, test_loader_fasttext, 3)\n",
        "fasttext_accuracy3, fasttext_f13 = evaluate_model2(fasttext_model3, test_loader_fasttext, 3)\n",
        "\n",
        "# Print the results\n",
        "print(\"T2 Model 1 Word2Vec Test Accuracy:\", word2vec_accuracy, \" Test F1 Score:\", word2vec_f1)\n",
        "print(\"T2 Model 1 GloVe Test Accuracy:\", glove_accuracy, \" Test F1 Score:\", glove_f1)\n",
        "print(\"T2 Model 1 Fasttext Test Accuracy:\", fasttext_accuracy, \" Test F1 Score:\", fasttext_f1)\n",
        "print(\"T2 Model 2 Word2Vec Test Accuracy:\", word2vec_accuracy2, \" Test F1 Score:\", word2vec_f12)\n",
        "print(\"T2 Model 2 GloVe Test Accuracy:\", glove_accuracy2, \" Test F1 Score:\", glove_f12)\n",
        "print(\"T2 Model 2 Fasttext Test Accuracy:\", fasttext_accuracy2, \" Test F1 Score:\", fasttext_f12)\n",
        "print(\"T2 Model 3 Word2Vec Test Accuracy:\", word2vec_accuracy3, \" Test F1 Score:\", word2vec_f13)\n",
        "print(\"T2 Model 3 GloVe Test Accuracy:\", glove_accuracy3, \" Test F1 Score:\", glove_f13)\n",
        "print(\"T2 Model 3 Fasttext Test Accuracy:\", fasttext_accuracy3, \" Test F1 Score:\", fasttext_f13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
